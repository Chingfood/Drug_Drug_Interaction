{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"scibert_embedding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOihCOLwHUF2IqSqZ8BD3mD"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOLow9YqGviB","executionInfo":{"status":"ok","timestamp":1615959844753,"user_tz":240,"elapsed":202,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"c0e21118-70d4-47f7-9948-1de3eb6f0af4"},"source":["from google.colab import files, drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yhf3wuSzNh1l","executionInfo":{"status":"ok","timestamp":1615959848982,"user_tz":240,"elapsed":3229,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"4f645c9c-f8b9-4629-dea9-49f8bd47b881"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.1)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5KLN6lmrHHPc"},"source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BzvG45hINt_N"},"source":["import pickle\n","import os\n","def save_obj(obj,path,name):\n","    with open(os.path.join(path, name + '.pkl'), 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(path):\n","    with open(path, 'rb') as f:\n","        return pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2xgMjKPKN7eH","executionInfo":{"status":"ok","timestamp":1615958515807,"user_tz":240,"elapsed":785,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"45f93d46-fc66-44fe-dfa8-7ebc80811723"},"source":["!ls /content/drive/MyDrive/DDI/test_features/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["bert_1\t\t      BioBert_embedding.ipynb\t  scibert_1\n","bert_2\t\t      data_text_features.pkl\t  scibert_2\n","bert_embedding.ipynb  ddi_test_id_w_features.pkl  scibert_embedding.ipynb\n","biobert_1\t      id_list.pkl\t\t  test_id_w_ground_truth.pkl\n","biobert_2\t      name_list.pkl\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FKn8-fuZNz6D"},"source":["data_text_features = load_obj(\"/content/drive/MyDrive/DDI/test_features/data_text_features.pkl\")\n","id_list = load_obj(\"/content/drive/MyDrive/DDI/test_features/id_list.pkl\")\n","id_list = [int(_) for _ in id_list]\n","test_id = load_obj(\"/content/drive/MyDrive/DDI/test_features/test_id_w_ground_truth.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvWABQYgOhzF"},"source":["#Mean Pooling - Take attention mask into account for correct averaging\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n","    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","    return sum_embeddings / sum_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdsZ6n6gOwZB"},"source":["def mean_pooling_2(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, [0,1])\n","    sum_mask = torch.clamp(input_mask_expanded.sum([0,1]), min=1e-9)\n","    return sum_embeddings.unsqueeze(0) / sum_mask.unsqueeze(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVvSndJeOziv"},"source":["#Sentences we want sentence embeddings for\n","sentences = ['This framework generates embeddings for each input sentence',\n","             'Sentences are passed as a list of string.',\n","             'The quick brown fox jumps over the lazy dog when it is raining.']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lvpq43fOPjH1"},"source":["tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n","model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RFByufcSP611"},"source":["#Tokenize sentences\n","encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=256, return_tensors='pt')\n","\n","#Compute token embeddings\n","with torch.no_grad():\n","    model_output = model(**encoded_input)\n","\n","#Perform pooling. In this case, mean pooling\n","sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"umdiuvKHzoxF"},"source":["len(data_text_features)"]},{"cell_type":"markdown","metadata":{"id":"dX8GdVTkomuV"},"source":["data = data_text_features[id_list.index(test_id[8])]"]},{"cell_type":"markdown","metadata":{"id":"Y3apj6ojowGC"},"source":["data[6]\n","striped_list = [_.strip() for _ in data[6]]\n","full_sent = ' '.join(striped_list)"]},{"cell_type":"markdown","metadata":{"id":"1avns7AsqUqW"},"source":["len(full_sent.split())"]},{"cell_type":"markdown","metadata":{"id":"53XMZju_ntaQ"},"source":["  sl = 0\n","  i = 8\n","  bert_embedding=[]\n","  bert_embedding_2 = []\n","  if i == 8:\n","      data_list = []\n","      data_list_2 = []\n","      data = data_text_features[id_list.index(test_id[i])]\n","      print(i)\n","      \n","      for j in range(2,len(data)):\n","          if j == 4:\n","              print(j)\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              \n","              if len(full_sent.split()) > 512:\n","                  encoded_input = tokenizer(striped_list, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              else:\n","                  encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1])\n","              continue\n","          elif j ==5:\n","              print(j)\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              if len(full_sent.split()) > 512:\n","                  encoded_input = tokenizer(striped_list, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              else:\n","                  encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1])\n","              continue\n","          elif j == 6:\n","              print(j)\n","              striped_list = [_.strip() for _ in data[j]]\n","              full_sent = ' '.join(striped_list)\n","              if len(full_sent.split()) > 2000:\n","                  strip_index = 0\n","                  strip_count = 0\n","                  for si in range(len(striped_list)):\n","                      strip_count += len(striped_list[si].split())\n","                      if strip_count < 2000:\n","                          strip_index = si \n","                      else:\n","                          break\n","              if len(striped_list) == 0: continue\n","              encoded_input = tokenizer(striped_list[:strip_index], padding=True, truncation=True, max_length=512, return_tensors='pt')\n","              #Compute token embeddings\n","              with torch.no_grad():\n","                  model_output = model(**encoded_input)\n","              #Perform pooling. In this case, mean pooling\n","              sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","              data_list.append(sentence_embeddings)\n","              data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              continue\n","          else:\n","              print(j)\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","              #Compute token embeddings\n","              with torch.no_grad():\n","                  model_output = model(**encoded_input)\n","              #Perform pooling. In this case, mean pooling\n","              sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","              data_list.append(sentence_embeddings)\n","              data_list_2.append(model_output[1])\n","              continue\n","      bert_embedding.append(np.array(torch.cat(data_list,0)))\n","      bert_embedding_2.append(np.array(torch.cat(data_list_2,0)))\n","  bert_np = np.array(bert_embedding)\n","  bert_np_2 = np.array(bert_embedding_2)\n","  savedex = sl//100\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_1/\"+str(savedex),bert_np)\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_2/\"+str(savedex),bert_np_2)"]},{"cell_type":"code","metadata":{"id":"4NJGTlziobJG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OBWlAiBRQOtc","executionInfo":{"status":"error","timestamp":1615970021517,"user_tz":240,"elapsed":8268209,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"a7477beb-622a-43fc-f73a-38802067ccf2"},"source":["for sl in range(0,len(test_id),100):\n","  bert_embedding=[]\n","  bert_embedding_2 = []\n","  for i in range(sl,min(sl+100,len(test_id))):\n","      data_list = []\n","      data_list_2 = []\n","      data = data_text_features[id_list.index(test_id[i])]\n","      print(i)\n","      \n","      for j in range(2,len(data)):\n","          if j == 4:\n","\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              \n","              if len(full_sent.split()) > 512:\n","                  if len(full_sent.split()) > 1000:\n","                      strip_index = 0\n","                      strip_count = 0\n","                      for si in range(len(striped_list)):\n","                          strip_count += len(striped_list[si].split())\n","                          if strip_count < 1000:\n","                              strip_index = si \n","                          else:\n","                              break\n","                      encoded_input = tokenizer(striped_list[:strip_index], padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  else:\n","                      encoded_input = tokenizer(striped_list, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  \n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              else:\n","                  encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1])\n","              continue\n","          elif j ==5:\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","\n","              if len(full_sent.split()) > 512:\n","                  if len(full_sent.split()) > 1000:\n","                      strip_index = 0\n","                      strip_count = 0\n","                      for si in range(len(striped_list)):\n","                          strip_count += len(striped_list[si].split())\n","                          if strip_count < 1000:\n","                              strip_index = si \n","                          else:\n","                              break\n","                      encoded_input = tokenizer(striped_list[:strip_index], padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  else:\n","                      encoded_input = tokenizer(striped_list, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              else:\n","                  encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","                  #Compute token embeddings\n","                  with torch.no_grad():\n","                      model_output = model(**encoded_input)\n","                  #Perform pooling. In this case, mean pooling\n","                  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","                  data_list.append(sentence_embeddings)\n","                  data_list_2.append(model_output[1])\n","              continue\n","          elif j == 6:\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              if len(full_sent.split()) > 1000:\n","                  strip_index = 0\n","                  strip_count = 0\n","                  for si in range(len(striped_list)):\n","                      strip_count += len(striped_list[si].split())\n","                      if strip_count < 1000:\n","                          strip_index = si \n","                      else:\n","                          break\n","                  encoded_input = tokenizer(striped_list[:strip_index], padding=True, truncation=True, max_length=512, return_tensors='pt')\n","              else:\n","                  encoded_input = tokenizer(striped_list, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","              #Compute token embeddings\n","              with torch.no_grad():\n","                  model_output = model(**encoded_input)\n","              #Perform pooling. In this case, mean pooling\n","              sentence_embeddings = mean_pooling_2(model_output, encoded_input['attention_mask'])\n","              data_list.append(sentence_embeddings)\n","              data_list_2.append(model_output[1].mean(0,keepdim=True))\n","              continue\n","          else:\n","              striped_list = [_.strip() for _ in data[j]]\n","              if len(striped_list) == 0: continue\n","              full_sent = ' '.join(striped_list)\n","              encoded_input = tokenizer(full_sent, padding=True, truncation=True, max_length=512, return_tensors='pt')\n","              #Compute token embeddings\n","              with torch.no_grad():\n","                  model_output = model(**encoded_input)\n","              #Perform pooling. In this case, mean pooling\n","              sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","              data_list.append(sentence_embeddings)\n","              data_list_2.append(model_output[1])\n","              continue\n","      bert_embedding.append(np.array(torch.cat(data_list,0)))\n","      bert_embedding_2.append(np.array(torch.cat(data_list_2,0)))\n","  bert_np = np.array(bert_embedding)\n","  bert_np_2 = np.array(bert_embedding_2)\n","  savedex = sl//100\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_1/\"+str(savedex),bert_np)\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_2/\"+str(savedex),bert_np_2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-2e18a86ef235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mdata_list_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_text_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"8l5PFoI6nfCz"},"source":["8"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VqPSkrcZJCq","executionInfo":{"status":"ok","timestamp":1615971370366,"user_tz":240,"elapsed":351,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"5b8a2113-0283-4aa3-c8fa-5e449c299052"},"source":["len(bert_embedding)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"K5PEYlGLZGNz"},"source":["  bert_np = np.array(bert_embedding)\n","  bert_np_2 = np.array(bert_embedding_2)\n","  savedex = sl//100\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_1/\"+str(savedex),bert_np)\n","  np.save(\"/content/drive/MyDrive/DDI/test_features/scibert_2/\"+str(savedex),bert_np_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QOD2BdJ70AT7","executionInfo":{"status":"ok","timestamp":1615961550085,"user_tz":240,"elapsed":214,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"398250e6-9d6c-4c3b-df99-5f0091f7bf31"},"source":["bert_embedding[8][-1,:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.85345651e-02,  5.15232235e-02, -4.43149328e-01,  2.13090718e-01,\n","       -9.25425440e-02, -2.99583495e-01,  3.35589916e-01,  3.53259265e-01,\n","       -4.38257456e-02,  1.26213774e-01,  4.89209861e-01,  1.06283084e-01,\n","       -4.88520354e-01, -4.09429014e-01, -4.15095717e-01, -4.27250922e-01,\n","       -6.22350499e-02, -8.13323408e-02,  4.04027134e-01, -2.74545878e-01,\n","        1.62152514e-01,  3.63494277e-01,  1.07574677e-02, -3.74525458e-01,\n","        4.20936912e-01,  6.33021832e-01, -2.13137254e-01, -1.72041170e-02,\n","       -2.65098453e-01,  2.25656211e-01, -2.66928375e-01, -1.46909043e-01,\n","       -3.95662427e-01, -7.28853405e-01,  2.35857889e-01,  3.17745835e-01,\n","        2.77955800e-01, -9.66640413e-02, -4.06908244e-01,  1.37640480e-02,\n","       -2.53298700e-01, -1.82540491e-01,  1.00070572e+00, -1.54397085e-01,\n","        1.43043548e-01, -1.76235139e-01, -1.25615835e-01,  4.36090052e-01,\n","        1.76823258e-01, -1.20980203e-01, -3.17457155e-03, -1.51602495e-02,\n","        8.32283720e-02,  4.58298951e-01,  2.49375254e-01, -2.05277562e-01,\n","       -4.60459292e-01, -2.83996910e-01, -8.05687234e-02, -4.04956602e-02,\n","       -2.90168792e-01,  3.24962698e-02, -3.28188725e-02,  2.30357260e-01,\n","        2.00529888e-01, -2.89041430e-01,  4.10978168e-01,  9.33619291e-02,\n","        5.03901124e-01,  2.16796547e-01, -3.47448476e-02,  8.14093873e-02,\n","        1.98988542e-01,  2.50448674e-01,  4.17151660e-01,  3.36026132e-01,\n","        1.87784195e-01,  4.04507339e-01, -4.15392727e-01, -4.10460420e-02,\n","       -1.90404236e-01, -7.37647414e-02, -1.11481696e-01, -1.25078827e-01,\n","       -1.03164323e-01,  3.28618914e-01, -8.36561173e-02, -5.21647297e-02,\n","       -1.57910064e-01,  2.50590831e-01,  3.11360359e-01,  3.28388810e-01,\n","        1.89385682e-01,  6.01151921e-02,  3.83876622e-01,  6.37411997e-02,\n","        2.99086452e-01, -9.33436528e-02, -8.73799101e-02,  4.50332940e-01,\n","       -5.52850142e-02,  1.23391412e-01,  3.86935472e-01,  2.60772049e-01,\n","        1.81340843e-01,  1.53820470e-01,  1.06787262e-02, -3.36471945e-01,\n","       -1.95135489e-01,  3.94350529e-01,  5.05909562e-01, -1.00839865e+00,\n","       -5.84734440e-01, -2.92862475e-01, -5.83990037e-01, -2.28938356e-01,\n","       -4.16351348e-01, -3.76235187e-01, -3.05759251e-01,  9.75833654e-01,\n","       -1.74770206e-01, -5.79229593e-01, -2.51609869e-02,  1.69488639e-01,\n","        2.36936510e-01,  2.94623315e-01,  2.03455374e-01, -3.70860279e-01,\n","        4.11610276e-01, -2.70948321e-01,  2.96558510e-03,  1.13845199e-01,\n","       -5.51456073e-03, -5.11641741e-01,  3.06830555e-01,  1.89737529e-01,\n","       -5.85912406e-01, -8.21172670e-02, -6.93427145e-01,  6.23990223e-02,\n","        5.31779602e-02,  2.42844611e-01,  3.67383122e-01,  6.37543976e-01,\n","        2.78490216e-01,  3.81336749e-01, -7.24386945e-02, -7.87711665e-02,\n","       -4.20749575e-01, -2.45223805e-01, -1.61326826e-01, -1.88358203e-02,\n","       -1.53955474e-01,  3.89877588e-01, -1.14040099e-01, -2.03529462e-01,\n","       -4.38119620e-01, -3.99522513e-01, -3.68691236e-01,  1.00701585e-01,\n","        2.73115367e-01, -4.60306734e-01,  1.16913378e-01,  2.48086408e-01,\n","       -2.27059811e-01, -8.65503028e-02, -3.43244880e-01,  1.63967118e-01,\n","       -1.60540625e-01, -6.41105650e-03, -3.67349051e-02, -1.62908081e-02,\n","        1.57277137e-01,  3.92825425e-01,  2.69682944e-01, -2.81674206e-01,\n","       -1.24593973e-01, -2.27543801e-01,  3.11339766e-01,  3.02054197e-01,\n","       -6.12778544e-01,  2.29717270e-01, -1.10091351e-01, -2.26196289e-01,\n","        4.51575480e-02, -4.65371907e-01,  3.30772698e-02,  5.72103672e-02,\n","       -2.09609926e-01, -3.28233331e-01,  3.11292976e-01,  2.73124903e-01,\n","        2.68188745e-01, -1.06352973e+00, -4.59826887e-01, -2.76458878e-02,\n","       -3.77197206e-01, -5.10775745e-01, -3.12558889e-01, -1.95871308e-01,\n","       -5.08771300e-01, -4.98052277e-02, -2.29615033e-01, -1.35093421e-01,\n","       -1.04431562e-01, -1.05481923e-01, -2.52329968e-02, -5.46909496e-02,\n","        3.04064602e-01, -2.91381687e-01, -3.62708181e-01, -3.33871126e-01,\n","        2.49158457e-01, -1.28826443e-02, -4.31698263e-01,  1.25227690e-01,\n","        2.34902203e-01,  2.24996917e-02, -1.95983887e-01,  9.45973024e-02,\n","        2.63432086e-01, -3.33597839e-01, -7.50087723e-02,  1.29716471e-01,\n","       -1.28712486e-02, -1.51165575e-01, -6.47790497e-03,  2.61336446e-01,\n","       -5.48648089e-02, -5.86237550e-01,  1.22712344e-01,  1.40842557e-01,\n","        3.08316559e-01,  3.56981009e-01,  5.85617304e-01, -1.62219420e-01,\n","        1.90070406e-01, -1.57993376e-01, -2.69794285e-01,  2.81863399e-02,\n","        1.98669001e-01,  2.74402440e-01,  6.33926690e-02,  7.52440616e-02,\n","       -2.49282226e-01, -4.85259145e-01,  1.52099445e-01,  4.43863422e-01,\n","        4.81013268e-01, -2.42454022e-01,  2.44390249e-01,  4.75472622e-02,\n","       -1.65630698e-01,  1.13167599e-01,  1.95464328e-01,  4.03853148e-01,\n","        3.62269342e-01,  3.49194467e-01,  3.58519435e-01, -6.04241014e-01,\n","        9.79004428e-02, -6.83267295e-01,  1.94096506e-01,  8.57567787e-01,\n","        4.62349467e-02, -5.20716682e-02,  1.31769776e-01,  1.00142220e-02,\n","       -1.49290442e-01, -1.33086853e-02,  8.88089836e-02, -1.75037295e-01,\n","       -4.20853384e-02, -6.92861617e-01, -2.84861438e-02,  3.78599942e-01,\n","        3.63390058e-01, -1.77279338e-01, -2.19876524e-02, -2.83093542e-01,\n","       -7.29985982e-02,  1.06465191e-01, -2.44096577e-01,  5.74756324e-01,\n","       -2.26320133e-01, -1.20863724e+00, -6.23847902e-01, -1.67630255e-01,\n","        3.42773259e-01, -3.39330375e-01,  6.78275526e-01, -1.40801191e-01,\n","        2.04122350e-01,  3.81731354e-02, -9.07151699e-02, -3.62548441e-01,\n","        4.68793958e-02, -4.10666056e-02,  4.85821277e-01,  2.05724865e-01,\n","        1.12772658e-01,  2.88246840e-01, -3.45895663e-02, -1.71519688e-03,\n","        6.57538772e-02, -4.60064054e-01, -1.19978376e-01, -2.04543337e-01,\n","       -1.50400624e-01,  4.85865474e-02,  5.29300943e-02, -5.08710682e-01,\n","        1.71678588e-01,  3.62895578e-02, -3.94503564e-01, -1.49983075e-02,\n","       -2.95184016e-01, -1.09076977e-01,  1.97854817e-01, -1.21066812e-02,\n","        5.11649512e-02, -1.37779921e-01, -1.71413720e-01, -3.61953713e-02,\n","       -4.77596931e-02,  2.18205117e-02,  2.67822817e-02,  1.31262625e-02,\n","       -1.99359670e-01, -3.53888273e-02,  1.33166179e-01,  4.37031910e-02,\n","       -1.72676980e-01,  1.95226893e-01,  1.87359557e-01, -6.74518421e-02,\n","        2.91446373e-02,  1.53728634e-01,  2.68248823e-02, -4.79885012e-01,\n","       -6.04791284e-01,  1.37659162e-01,  3.38705003e-01,  2.14867573e-02,\n","        7.40988135e-01, -3.96906376e-01, -6.66417837e-01,  4.04590309e-01,\n","       -1.35683179e-01,  4.77359183e-02,  1.85281709e-01,  2.77844846e-01,\n","        6.32647052e-02, -9.90477875e-02, -4.29488182e-01,  1.87481567e-01,\n","       -1.48744166e-01, -1.70039073e-01,  2.37676874e-02,  6.70359194e-01,\n","       -5.44170737e-01, -9.56032723e-02, -2.35145748e-01,  3.45240198e-02,\n","        4.05883431e-01,  3.09583265e-02,  9.48578656e-01, -2.74185151e-01,\n","       -2.08246976e-01, -2.38908738e-01, -3.44007939e-01, -1.53807536e-01,\n","        3.57733041e-01,  5.52240163e-02,  5.82282603e-01,  1.89883292e-01,\n","        2.97441304e-01, -3.45513016e-01, -9.96372849e-03,  3.97836626e-01,\n","        2.82099903e-01,  1.31594896e-01, -2.02546284e-01, -2.48296276e-01,\n","        1.44559518e-01,  3.89496982e-01,  2.53653705e-01,  1.82099000e-01,\n","        6.15135320e-02,  1.56502694e-01, -8.79809186e-02,  1.53697506e-01,\n","       -6.52482212e-02,  6.66843712e-01,  3.17284167e-01, -1.74762681e-01,\n","        2.40809545e-01,  3.84437889e-01,  1.68947443e-01,  1.54285198e-02,\n","        3.59856218e-01, -1.24030933e-01, -9.51967299e-01, -8.89980569e-02,\n","       -1.87825456e-01,  1.13674209e-01, -2.64497161e-01,  1.57164717e+00,\n","        1.50869817e-01,  5.14043093e-01,  2.42540717e-01, -8.99144039e-02,\n","        2.68520147e-01,  1.06798671e-01, -2.64161110e-01, -2.75645167e-01,\n","        2.39982054e-01,  1.89049616e-01,  4.68414798e-02, -7.99581409e-03,\n","       -3.97907905e-02,  1.04692027e-01,  1.14225445e+01, -1.07864931e-01,\n","       -1.12878084e+00, -1.41842410e-01,  1.19334850e-02, -4.47125077e-01,\n","       -1.75362200e-01, -4.17758189e-02, -4.58275340e-02,  1.60760939e-01,\n","        1.23812459e-01,  2.31907144e-01,  2.92218626e-01,  3.46897572e-01,\n","        2.65063465e-01, -4.65710223e-01, -4.50602442e-01,  3.28625768e-01,\n","        2.72226900e-01, -6.02533817e-01, -7.15150088e-02,  1.51749611e-01,\n","       -2.60123044e-01,  4.21403348e-01,  2.03415066e-01,  9.70538110e-02,\n","        2.31592685e-01, -6.09987564e-02, -3.09605170e-02, -5.50037861e-01,\n","        5.81405342e-01, -4.20564711e-01,  3.79515260e-01,  1.65060952e-01,\n","       -5.71109913e-03, -1.98701024e-01,  4.06675577e-01,  2.50029191e-02,\n","       -3.58834341e-02,  8.41250718e-02, -3.42510581e-01,  5.63842691e-02,\n","        1.48236334e-01,  1.90570541e-02, -2.58763969e-01,  1.76002041e-01,\n","        8.70847404e-02,  3.32357347e-01, -5.27187347e-01, -6.94141805e-01,\n","        1.01606108e-01,  3.73948544e-01, -2.40790099e-02, -3.00987244e-01,\n","       -4.64498758e-01,  4.51140434e-01, -2.53694445e-01, -1.79789029e-02,\n","       -3.97332549e-01,  2.11299449e-01, -5.82054071e-02,  6.07851595e-02,\n","       -2.06652418e-01,  4.82880622e-01, -2.98835248e-01,  3.12890917e-01,\n","       -4.47805017e-01, -3.49353254e-01,  2.65639514e-01,  7.53474906e-02,\n","       -5.51314890e-01, -7.11720228e-01, -3.25456828e-01,  1.95764557e-01,\n","       -5.20223737e-01,  7.78303593e-02, -4.09163803e-01, -2.62275130e-01,\n","       -1.48020670e-01, -1.51190639e-01,  1.45458549e-01,  5.06640635e-02,\n","        6.96059689e-02,  1.08088359e-01, -5.74959099e-01, -4.57095087e-01,\n","        2.04471320e-01,  1.07918993e-01, -2.06051134e-02,  9.20666605e-02,\n","       -2.58665055e-01, -6.32316098e-02, -1.68893993e-01,  2.30468571e-01,\n","       -4.21511143e-01, -2.20498830e-01,  3.49565446e-02, -2.13704720e-01,\n","       -3.20309818e-01,  2.33724371e-01,  7.23415315e-02,  1.46461949e-01,\n","        4.34248507e-01,  1.46263599e-01, -7.74241686e-02,  1.97427586e-01,\n","       -3.13936740e-01,  2.03178331e-01, -1.89116418e-01,  1.53773772e-02,\n","        1.29695460e-01, -4.89577055e-01,  2.83287019e-01, -2.44831473e-01,\n","        1.58949196e-02,  9.57260355e-02, -2.69617766e-01, -2.32674405e-02,\n","       -3.42961580e-01,  4.62959819e-02,  4.42151934e-01,  4.07092363e-01,\n","        9.98786390e-02,  1.67159680e-02, -3.93928021e-01,  1.22737966e-01,\n","       -1.76892966e-01, -3.70434016e-01, -1.31570458e-01,  1.54246360e-01,\n","        1.57045856e-01, -2.91545630e-01, -4.99256045e-01,  4.74974424e-01,\n","        4.65064794e-02,  1.25299230e-01, -8.65016729e-02,  1.25751540e-01,\n","        2.12332353e-01, -2.62841377e-02, -2.72418439e-01, -1.59300417e-01,\n","       -3.34651083e-01, -1.43970087e-01,  5.93494594e-01,  2.34581143e-01,\n","        1.78470969e-01, -2.57399797e-01,  3.58505905e-01,  5.60834348e-01,\n","        2.82771081e-01, -2.83212602e-01, -2.57014453e-01,  2.19196767e-01,\n","        5.41280210e-02,  4.60477561e-01,  3.42106670e-01, -1.38802260e-01,\n","        2.00779304e-01, -6.02984242e-02,  3.97246443e-02,  2.54588932e-01,\n","       -1.77722916e-01, -1.97148740e-01,  3.65494601e-02, -5.04655689e-02,\n","       -3.50141376e-01, -2.86385030e-01,  1.32179186e-01, -1.50228590e-01,\n","       -5.22249565e-02, -2.95467209e-02, -6.02126181e-01, -4.47371989e-01,\n","       -2.32569221e-02, -2.30625153e-01, -1.00521833e-01,  4.18681502e-01,\n","       -3.11284482e-01,  4.76025082e-02, -1.62511200e-01,  2.14826137e-01,\n","       -1.79248173e-02,  2.35326830e-02,  1.84702992e-01, -2.81427413e-01,\n","       -1.71782095e-02, -2.53080372e-02, -6.43016398e-01,  1.95004884e-02,\n","        6.56819940e-01, -3.18774849e-01, -2.52919167e-01, -3.26543540e-01,\n","       -3.58458489e-01,  5.55409014e-01, -1.76349893e-01, -3.78562063e-01,\n","       -2.80175470e-02, -3.20844829e-01,  2.84255862e-01, -6.73414409e-01,\n","        3.03758055e-01,  1.36090338e-01, -7.00584892e-03,  3.53057325e-01,\n","        8.01328644e-02,  2.70991564e-01, -3.27085882e-01, -1.69531479e-01,\n","        3.05574993e-03, -8.06263164e-02,  1.72195509e-02,  1.34806195e-03,\n","       -3.97507787e-01,  1.84494212e-01, -1.12081766e+00,  1.13010786e-01,\n","       -3.69010866e-02,  6.48336709e-02, -1.94069535e-01, -5.39442539e-01,\n","       -8.82122219e-01,  2.66575031e-02,  5.28765500e-01,  2.80376732e-01,\n","       -2.81595886e-01, -2.42917478e-01,  2.02955022e-01, -2.43729800e-01,\n","        1.94361582e-01, -2.46846378e-01,  1.29109785e-01,  3.48668188e-01,\n","       -5.71784914e-01,  5.41579545e-01,  1.99483693e-01,  2.47173637e-01,\n","       -3.19845408e-01,  3.48486960e-01,  2.45367125e-01,  2.89294749e-01,\n","        1.38237223e-01,  6.13010004e-02,  2.23032624e-01,  4.77986671e-02,\n","        2.06624076e-01, -1.25045314e-01, -4.83310491e-01, -4.89813238e-02,\n","        2.23215252e-01,  3.54821920e-01,  2.85233647e-01,  2.02748418e-01,\n","       -5.77177405e-01, -9.79983285e-02, -1.73830152e-01, -6.51580021e-02,\n","        5.30101299e-01,  2.08804652e-01,  1.93016902e-01,  7.98826367e-02,\n","        2.09149659e-01, -5.52646816e-02, -4.44826663e-01,  5.11614919e-01,\n","        4.56819758e-02,  9.81535539e-02, -6.21882491e-02, -1.77075237e-01,\n","       -2.12892398e-01,  7.52296224e-02,  4.09630895e-01, -3.26726943e-01,\n","        5.24530828e-01,  2.66057346e-02,  2.13071480e-01,  2.19973326e-02,\n","        8.05404544e-01,  2.14707851e-01,  1.08596504e-01,  4.78379190e-01,\n","       -3.83613929e-02, -1.86487123e-01, -6.59833848e-02, -4.99427676e-01,\n","       -1.83014616e-01,  2.40365833e-01, -3.67054850e-01,  1.15359880e-01,\n","        1.44404054e-01, -1.34464547e-01, -2.20135208e-02, -1.60030544e-01,\n","       -9.80674028e-02,  8.88637528e-02, -1.76724941e-01, -3.62806022e-02,\n","        1.35604665e-01, -1.42548874e-01, -7.97745287e-02,  3.06591272e-01,\n","       -2.13863164e-01, -1.39367774e-01,  5.28610349e-01,  2.90362060e-01,\n","        3.44526768e-01, -4.77435768e-01,  2.13205487e-01,  4.26440209e-01,\n","        3.25190872e-01,  3.85440439e-02, -2.05353782e-01,  3.54537666e-01,\n","        5.71797490e-02,  7.40353525e-01,  4.08386528e-01,  3.00339133e-01,\n","        1.87639847e-01, -9.76672322e-02,  2.22363863e-02, -6.18151188e-01,\n","       -2.83316195e-01,  3.62096101e-01,  9.16702598e-02,  1.15946651e-01,\n","        7.46089295e-02, -2.62776941e-01, -6.02281868e-01, -4.54561293e-01,\n","        1.90124661e-01, -6.95910975e-02, -3.39353904e-02,  9.26690519e-01,\n","       -1.90935731e-01, -4.35877800e-01,  3.86641115e-01,  2.43411019e-01,\n","        8.01411271e-03, -3.83993983e-01, -6.24427497e-01, -1.73236310e-01,\n","       -7.50740841e-02, -4.12107050e-01, -6.53743863e-01, -7.22031176e-01],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"guPb_2PqdlvD"},"source":["bert_np = np.array(bert_embedding)\n","bert_np_2 = np.array(bert_embedding_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BW8fbZlldqgr"},"source":["np.save(\"/content/drive/MyDrive/DDI/training/SciBert/0\",bert_np[:-2,:,:])\n","np.save(\"/content/drive/MyDrive/DDI/training/SciBert_2/0\",bert_np_2[:-2,:,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cDKoNMM5xncx","executionInfo":{"status":"ok","timestamp":1615944125288,"user_tz":240,"elapsed":203,"user":{"displayName":"Chingyuen Liu","photoUrl":"","userId":"05190519383060638517"}},"outputId":"c33793d5-dab5-48b3-a78b-cdcc30fe60ae"},"source":["bert_np.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(352, 5, 768)"]},"metadata":{"tags":[]},"execution_count":34}]}]}